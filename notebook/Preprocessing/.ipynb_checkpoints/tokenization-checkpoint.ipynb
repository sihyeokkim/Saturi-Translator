{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "def49c8d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import sentencepiece as spm\n",
    "import numpy as np\n",
    "import os\n",
    "from konlpy.tag import Mecab"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "6111e9a5",
   "metadata": {},
   "outputs": [],
   "source": [
    "dir_path = os.getenv(\"HOME\") +'/aiffel/DATA'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "9431a0c1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['corpus_dec_8009.txt',\n",
       " 'data_train_spm_4000_0317.pkl',\n",
       " 'corpus_enc_8009.txt',\n",
       " 'test_results_spm4000.csv',\n",
       " 'test_v_final_0313.csv',\n",
       " 'train_v_final_0317.csv',\n",
       " 'corpus_dec_r0.txt',\n",
       " '.ipynb_checkpoints',\n",
       " 'data_test_msp_4000_0320.pkl',\n",
       " 'data_test_spm_4000_0317.pkl',\n",
       " 'data_test_spm_4000.pkl',\n",
       " 'data_train_spm_4000.pkl',\n",
       " 'corpus_enc_r0.txt',\n",
       " 'data_train_msp_4000_0320.pkl',\n",
       " 'train_v_final_0313.csv',\n",
       " 'test_results_msp4000.csv',\n",
       " 'test_v_final_0317.csv',\n",
       " 'corpus_dec_mecab_4009.txt']"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "os.listdir(dir_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "5394d0b3",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train=pd.read_csv(dir_path + '/train_v_final_0317.csv')\n",
    "df_test=pd.read_csv(dir_path + '/test_v_final_0317.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "53c20b2e",
   "metadata": {},
   "outputs": [],
   "source": [
    "mecab = Mecab()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "9967d622",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1340262/1340262 [04:05<00:00, 5450.38it/s]\n"
     ]
    }
   ],
   "source": [
    "import tqdm\n",
    "m_dial = []\n",
    "dial_text = df_train.dial.values\n",
    "for i in tqdm.tqdm(dial_text) :\n",
    "    temp_ = mecab.morphs(i)\n",
    "    m_dial.append(' '.join(temp_))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "3df635f6",
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_tokenizer(corpus, vocab_size, lang=\"en\", pad_id=0, bos_id=1, eos_id=2, unk_id=3):\n",
    "\n",
    "    temp_file = os.getenv('HOME') + f'/aiffel/DATA/corpus_{lang}.txt'     # corpus를 받아 txt파일로 저장\n",
    "    \n",
    "    with open(temp_file, 'w') as f:\n",
    "        for row in corpus:\n",
    "            f.write(str(row) + '\\n')\n",
    "    \n",
    "    # Sentencepiece를 이용해 \n",
    "    spm.SentencePieceTrainer.Train(\n",
    "        f'--input={temp_file} --pad_id={pad_id} --bos_id={bos_id} --eos_id={eos_id} \\\n",
    "        --unk_id={unk_id} --model_prefix=spm_{lang} --vocab_size={vocab_size} --model_type=bpe \\\n",
    "        --user_defined_symbols=<jj>,<jd>,<gs>,<cc>,<kw>'   # model_r1\n",
    "    )\n",
    "    tokenizer = spm.SentencePieceProcessor()\n",
    "    tokenizer.Load(f'spm_{lang}.model') # model_r1\n",
    "\n",
    "    return tokenizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "4b05bed9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# enc_tokenizer = generate_tokenizer(df_train.dial.values, 4009, lang ='enc_8009')\n",
    "dec_tokenizer = generate_tokenizer(m_dial, 4009, lang = 'dec_custom_mecab_4009')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "17a52342",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dir_path = os.getenv(\"HOME\") + '/aiffel/saturi/notebook/Model/'\n",
    "\n",
    "enc_tokenizer = spm.SentencePieceProcessor()\n",
    "enc_tokenizer.Load(dir_path + 'spm_enc_v.model')\n",
    "\n",
    "dec_tokenizer_old = spm.SentencePieceProcessor()\n",
    "dec_tokenizer_old.Load(dir_path + 'spm_dec_v.model')\n",
    "\n",
    "dec_tokenizer_msp = spm.SentencePieceProcessor()\n",
    "dec_tokenizer_msp.Load('spm_dec_mecab_4009.model')\n",
    "\n",
    "dec_tokenizer.set_encode_extra_options(\"bos:eos\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "8dc84523",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train['eng'] = '<'+df_train['reg']+'> ' + df_train['eng']\n",
    "df_test['eng'] = '<'+df_test['reg']+'> ' + df_test['eng']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "203d2ace",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>reg</th>\n",
       "      <th>topic</th>\n",
       "      <th>eng</th>\n",
       "      <th>dial</th>\n",
       "      <th>tok_len</th>\n",
       "      <th>tok_cat</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>jd</td>\n",
       "      <td>역사</td>\n",
       "      <td>&lt;jd&gt; I've changed my mind a little bit.</td>\n",
       "      <td>생각이 쪼금씩 바뀌드라고</td>\n",
       "      <td>10</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>jd</td>\n",
       "      <td>가족</td>\n",
       "      <td>&lt;jd&gt; You know what? Foreigners still get used ...</td>\n",
       "      <td>웜마 알겄는가 애국인들이 그또 달 적응하고</td>\n",
       "      <td>17</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>jd</td>\n",
       "      <td>건강</td>\n",
       "      <td>&lt;jd&gt; All of a sudden, I think I've ripped off ...</td>\n",
       "      <td>아으 갑자기 에전에 맹장 뜯은 게잉 생각난디야.</td>\n",
       "      <td>22</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>jd</td>\n",
       "      <td>스타일</td>\n",
       "      <td>&lt;jd&gt; I have a lot of ideas about getting older...</td>\n",
       "      <td>보먼은 좀 품위 있게 나이 들어가야 되겠단 싱각을 참 마이 해요잉.</td>\n",
       "      <td>18</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>jd</td>\n",
       "      <td>먹거리</td>\n",
       "      <td>&lt;jd&gt; It's a little bit of a tastey, but still...</td>\n",
       "      <td>약깐 좀 약깐 맛이가 쪼까 머시기 카긴 한디 그또</td>\n",
       "      <td>18</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  reg topic                                                eng  \\\n",
       "0  jd    역사            <jd> I've changed my mind a little bit.   \n",
       "1  jd    가족  <jd> You know what? Foreigners still get used ...   \n",
       "2  jd    건강  <jd> All of a sudden, I think I've ripped off ...   \n",
       "3  jd   스타일  <jd> I have a lot of ideas about getting older...   \n",
       "4  jd   먹거리   <jd> It's a little bit of a tastey, but still...   \n",
       "\n",
       "                                     dial  tok_len  tok_cat  \n",
       "0                          생각이 쪼금씩 바뀌드라고        10        1  \n",
       "1                웜마 알겄는가 애국인들이 그또 달 적응하고        17        1  \n",
       "2             아으 갑자기 에전에 맹장 뜯은 게잉 생각난디야.        22        1  \n",
       "3  보먼은 좀 품위 있게 나이 들어가야 되겠단 싱각을 참 마이 해요잉.        18        1  \n",
       "4            약깐 좀 약깐 맛이가 쪼까 머시기 카긴 한디 그또        18        1  "
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_train.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2d28ebe7",
   "metadata": {},
   "source": [
    " 0.   toks_en     \n",
    " 1.   toks_dec    \n",
    " 2.   source_txt  \n",
    " 3.   target_txt  \n",
    " 4.   topic       \n",
    " 5.   reg         "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "30de9f44",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'생각이 쪼금씩 바뀌드라고 '"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_train.dial.values[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "f1bc28b8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['▁생각이', '▁쪼', '금', '씩', '▁바', '뀌', '드라고', '▁']"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# spm\n",
    "dec_tokenizer_old.encode_as_pieces(df_train.dial.values[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "12576cfc",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['▁생각', '이', '▁쪼금', '씩', '▁바뀌', '드', '라고']"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# msp\n",
    "dec_tokenizer_msp.encode_as_pieces(df_train.dial.values[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "dc5a47dd",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['<s>', '▁생각', '이', '▁쪼금', '씩', '▁바뀌', '드라고', '</s>']"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# custom msp\n",
    "dec_tokenizer.encode_as_pieces(df_train.dial.values[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "30e3469f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tqdm\n",
    "def tokenize_data(df) :\n",
    "    dial_text = df['dial'].values\n",
    "    eng_text = df['eng'].values\n",
    "\n",
    "    toks_en = []\n",
    "    toks_dec = []\n",
    "\n",
    "    for i in tqdm.tqdm(range(len(df))) :\n",
    "        \n",
    "        en_tokenized = enc_tokenizer.encode(eng_text[i])\n",
    "        dial_tokenized = dec_tokenizer.encode(dial_text[i])\n",
    "        toks_en.append(en_tokenized)\n",
    "        toks_dec.append(dial_tokenized)\n",
    "    \n",
    "    df['toks_en'] = toks_en\n",
    "    df['toks_dec'] = toks_dec"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "39af5f68",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1500/1500 [00:00<00:00, 3449.42it/s]\n",
      "100%|██████████| 1340262/1340262 [02:42<00:00, 8251.75it/s]\n"
     ]
    }
   ],
   "source": [
    "for i in [df_test, df_train]:\n",
    "    tokenize_data(i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "e5ea2446",
   "metadata": {},
   "outputs": [],
   "source": [
    "dir_path = os.getenv(\"HOME\") +'/aiffel/DATA'\n",
    "df_train.to_pickle(dir_path + '/data_train_custom_msp_4000_0321.pkl','gzip')\n",
    "df_test.to_pickle(dir_path + '/data_test_custom_msp_4000_0321.pkl','gzip')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a67bf919",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
